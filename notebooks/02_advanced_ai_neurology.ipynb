{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPgLYOzI3lDs9Ww6i+0uQTX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mdelleani/neuro-next-bootcamp/blob/main/notebooks/02_advanced_ai_neurology.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "yGUtddnciENO"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/mdelleani/neuro-next-bootcamp.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Applicazioni Avanzate dell'IA in Neurologia: Dalla Segmentazione Immagini ai LLM üß†\n",
        "\n",
        "**Sessione Interattiva | Parte II: Applicazioni Pratiche**\n",
        "\n",
        "* **Docente:** M. Delleani\n",
        "* **Orario:** 18:00 - 19:15\n",
        "\n",
        "---\n",
        "\n",
        "Benvenuti alla seconda parte della nostra sessione interattiva!\n",
        "\n",
        "Mentre il titolo originale della sessione era focalizzato sulla generazione di dati sintetici, per questa demo pratica abbiamo scelto di esplorare due aree di frontiera dell'Intelligenza Artificiale con un impatto immediato e tangibile in Neurologia, pi√π facilmente dimostrabili in un contesto di sessione interattiva:\n",
        "\n",
        "\n",
        "1.  **Large Language Models (LLM) per l'Analisi Testuale:** Come i modelli di linguaggio possono elaborare e interpretare testo medico (es. cartelle cliniche, articoli scientifici) per estrarre informazioni chiave, riassumere o rispondere a domande.\n",
        "2.  **Segmentazione di Immagini Mediche:** Come l'IA pu√≤ aiutare a identificare e delineare automaticamente strutture o patologie (es. lesioni, tumori, regioni cerebrali) nelle immagini diagnostiche (RM, TC).\n",
        "\n",
        "Queste applicazioni mostrano la versatilit√† e il potenziale dell'IA nel supportare la diagnosi, la ricerca e la gestione clinica in neurologia.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "pUIphWGwiRWI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Large Language Models (LLM) per l'Analisi Testuale in Neurologia\n",
        "I Large Language Models (LLM) sono modelli di IA addestrati su enormi quantit√† di testo per comprendere, generare e manipolare il linguaggio umano. Hanno rivoluzionato il modo in cui interagiamo con l'informazione e stanno mostrando un potenziale immenso anche nel settore medico.\n"
      ],
      "metadata": {
        "id": "jKep_WWWnEUt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### 1.1. Applicazioni degli LLM in Medicina e Neurologia\n",
        "\n",
        "- Riassunto di Cartelle Cliniche/Articoli: Estrarre i punti chiave da lunghi testi.\n",
        "\n",
        "- Estrazione di Informazioni: Identificare sintomi, diagnosi, farmaci, dosaggi da testi non strutturati.\n",
        "\n",
        "- Supporto Decisionale Clinico: Fornire informazioni basate sull'evidenza da banche dati mediche (con cautela).\n",
        "\n",
        "- Generazione di Rapporti: Aiutare a redigere referti o documentazione.\n",
        "Analisi di Testi Scientifici: Accelerare la revisione della letteratura.\n"
      ],
      "metadata": {
        "id": "mQXFuiCanSmA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### 1.2. Interagire con LLM Generali e Specializzati\n",
        "\n",
        "Avremo la possibilit√† di interagire con un server di inferenza ad alte prestazioni per LLMche ci permetter√† di testare rapidamente modelli di linguaggio.\n",
        "\n",
        "Useremo un approccio basato su API (Application Programming Interface), simulando una chiamata a un servizio esterno che ospita il modello."
      ],
      "metadata": {
        "id": "lgna9NzQnUiv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Esempio testo in Neurologia**"
      ],
      "metadata": {
        "id": "QUN4lC1rnn87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testo_clinico_neurologia = \"\"\"\n",
        "Paziente M.D., 72 anni, ricoverato per peggioramento delle difficolt√† cognitive iniziate 6 mesi fa,\n",
        "caratterizzate principalmente da deficit di memoria episodica, disorientamento temporale e spaziale.\n",
        "L'esame neurologico evidenzia lieve disprassia costruttiva. La RM cerebrale mostra atrofia ippocampale\n",
        "bilaterale e una modesta componente vascolare. CSF positivo per biomarker di Alzheimer (ridotta AŒ≤42, aumentata p-tau).\n",
        "Diagnosi provvisoria: Demenza di tipo Alzheimer con componente vascolare. Iniziato trattamento con Donepezil 5mg/die.\n",
        "Si programma follow-up tra 3 mesi.\n",
        "\"\"\"\n",
        "\n",
        "testo_articolo_neurologia = \"\"\"\n",
        "Uno studio recente ha esplorato l'efficacia di un nuovo anticorpo monoclonale, Aducanumab,\n",
        "nel ridurre le placche amiloidi nel cervello di pazienti affetti da Alzheimer in fase precoce.\n",
        "I risultati preliminari indicano una riduzione significativa del carico di amiloide,\n",
        "tuttavia, la correlazione con il miglioramento clinico rimane oggetto di dibattito,\n",
        "con alcuni pazienti che riportano eventi avversi come ARIA-E. La ricerca √® stata pubblicata\n",
        "su \"Nature Neuroscience\".\n",
        "\"\"\"\n",
        "\n",
        "print(\"Testo Clinico di Esempio:\")\n",
        "print(testo_clinico_neurologia)\n",
        "print(\"\\nTesto Articolo Scientifico di Esempio:\")\n",
        "print(testo_articolo_neurologia)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fB4CH_qbmw-D",
        "outputId": "8f17cc18-4fe2-4f79-b8fd-77bdbfbd6da6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testo Clinico di Esempio:\n",
            "\n",
            "Paziente M.D., 72 anni, ricoverato per peggioramento delle difficolt√† cognitive iniziate 6 mesi fa,\n",
            "caratterizzate principalmente da deficit di memoria episodica, disorientamento temporale e spaziale.\n",
            "L'esame neurologico evidenzia lieve disprassia costruttiva. La RM cerebrale mostra atrofia ippocampale\n",
            "bilaterale e una modesta componente vascolare. CSF positivo per biomarker di Alzheimer (ridotta AŒ≤42, aumentata p-tau).\n",
            "Diagnosi provvisoria: Demenza di tipo Alzheimer con componente vascolare. Iniziato trattamento con Donepezil 5mg/die.\n",
            "Si programma follow-up tra 3 mesi.\n",
            "\n",
            "\n",
            "Testo Articolo Scientifico di Esempio:\n",
            "\n",
            "Uno studio recente ha esplorato l'efficacia di un nuovo anticorpo monoclonale, Aducanumab,\n",
            "nel ridurre le placche amiloidi nel cervello di pazienti affetti da Alzheimer in fase precoce.\n",
            "I risultati preliminari indicano una riduzione significativa del carico di amiloide,\n",
            "tuttavia, la correlazione con il miglioramento clinico rimane oggetto di dibattito,\n",
            "con alcuni pazienti che riportano eventi avversi come ARIA-E. La ricerca √® stata pubblicata\n",
            "su \"Nature Neuroscience\".\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Funzione per Chiamare un LLM (via API)**\n",
        "\n",
        "Simuleremo una chiamata API al tuo server vLLM. Dovrai sostituire YOUR_VLLM_ENDPOINT e YOUR_MODEL_NAME con i dettagli reali del tuo setup vLLM."
      ],
      "metadata": {
        "id": "_h5jR0rLoZI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd neuro-next-bootcamp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ok43rG_F9QXa",
        "outputId": "e736b207-6553-40f3-ec75-45bc08c288b4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/neuro-next-bootcamp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testo_referto = testo_clinico_neurologia\n",
        "informazioni_da_estrarre = \"motivo vista, diagnosi, sintomi, trattamento consigliato, imaging, anamnesi\""
      ],
      "metadata": {
        "id": "v2bb_p1C-awe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from notebooks.utils import ask_generalist_llm, ask_specialized_llm\n",
        "import asyncio\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": \"Sei un assistente medico neurologo.\"}]},\n",
        "    {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": f\"Dato il Referto: {testo_referto}\\n\\nEstrai: {informazioni_da_estrarre}\"}]}\n",
        "]\n",
        "\n",
        "# Run one or the other\n",
        "response = await ask_generalist_llm(messages)\n",
        "\n",
        "print(\"Risposta del modello generalista:\\n\", response)\n"
      ],
      "metadata": {
        "id": "RdYSZ__BnrFh",
        "outputId": "35dafc9f-f9c2-491e-c562-6a112cb0d8e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Risposta del modello generalista:\n",
            "  - Motivo vista: Peggioramento delle difficolt√† cognitive iniziate 6 mesi fa.\n",
            "\n",
            "- Diagnosi: Demenza di tipo Alzheimer con componente vascolare.\n",
            "\n",
            "- Sintomi: Deficit di memoria episodica, disorientamento temporale e spaziale, lieve disprassia costruttiva.\n",
            "\n",
            "- Trattamento consigliato: Iniziato trattamento con Donepezil 5mg/die.\n",
            "\n",
            "- Imaging: RM cerebrale mostra atrofia ippocampale bilaterale e una modesta componente vascolare.\n",
            "\n",
            "- Anamnesi: Paziente M.D., 72 anni.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_specialized = await ask_specialized_llm(messages)\n",
        "\n",
        "print(\"Risposta del modello specializzato:\\n\", response_specialized)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DOLzH_5950V",
        "outputId": "9225fe09-4258-49c7-baf7-e22814ddf3c1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Risposta del modello specializzato:\n",
            " Errore di connessione al server vLLM. Assicurati che l'endpoint sia corretto e il server sia attivo.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 2. Prompt few-shot + nuovo referto\n",
        "few_shot_examples = \"\"\"\n",
        "Referto:\n",
        "Paziente maschio di 52 anni con cefalea intensa, nausea e rigidit√† nucale. RM encefalo mostra emorragia subaracnoidea. Inizia trattamento in neurochirurgia. Diagnosi: emorragia subaracnoidea.\n",
        "\n",
        "Risposta:\n",
        "Diagnosi: Emorragia subaracnoidea\n",
        "Sintomi principali: Cefalea intensa, nausea, rigidit√† nucale\n",
        "Trattamento consigliato: Osservazione e valutazione neurochirurgica\n",
        "Imaging anomalo: s√¨, emorragia subaracnoidea alla RM\n",
        "\n",
        "---\n",
        "\n",
        "Referto:\n",
        "Donna di 74 anni con progressiva perdita di memoria, disorientamento temporale e alterazioni comportamentali. TC encefalo: atrofia diffusa. Diagnosi probabile: demenza di Alzheimer. Inizia trattamento con donepezil.\n",
        "\n",
        "Risposta:\n",
        "Diagnosi: Demenza di Alzheimer (probabile)\n",
        "Sintomi principali: Perdita di memoria, disorientamento, alterazioni comportamentali\n",
        "Trattamento consigliato: Donepezil\n",
        "Imaging anomalo: s√¨, atrofia diffusa alla TC\n",
        "\n",
        "---\n",
        "\n",
        "Referto:\n",
        "Paziente di 67 anni giunge in PS per insorgenza improvvisa di emiparesi destra e disartria. TC encefalo negativa. RM encefalo mostra lesione ischemica recente in territorio lenticolo-capsulare sinistro. Inizia trattamento con ASA e statine. Diagnosi: ictus ischemico in paziente ipertesa.\n",
        "\n",
        "Risposta:\n",
        "\"\"\"\n",
        "\n",
        "prompt = few_shot_examples.strip()"
      ],
      "metadata": {
        "id": "f2CTiQDv6Qul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt"
      ],
      "metadata": {
        "id": "tSPptT046SuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if VLLM_ENDPOINT is None:\n",
        "    print(\"\\nSkipping LLM demo: Please configure VLLM_ENDPOINT in the cell above.\")\n",
        "else:\n",
        "    print(\"\\n--- Riassunto di Testo (Modello Generalista) ---\")\n",
        "    prompt_riassunto_clinico = f\"Riassumi il seguente testo clinico in 2-3 frasi:\\n\\n{testo_clinico_neurologia}\\n\\nRiassunto:\"\n",
        "    riassunto_generalista =  await call_llm(prompt_riassunto_clinico, GENERALIST_MODEL_NAME)\n",
        "    print(f\"\\nPrompt: {prompt_riassunto_clinico[:]}\") # Stampa solo l'inizio del prompt\n",
        "    print(f\"Risposta (Generalista):\")\n",
        "    for i in range(0, len(riassunto_generalista), 100):\n",
        "      print(riassunto_generalista[i:i+100])"
      ],
      "metadata": {
        "id": "pDBDhqjzP-4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel\n",
        "from enum import Enum\n",
        "\n",
        "\n",
        "import requests\n",
        "import json\n",
        "import httpx\n",
        "\n",
        "\n",
        "HOST = \"35.240.108.178\"\n",
        "PORT = 8000\n",
        "\n",
        "# --- CONFIGURAZIONE DEL TUO VLLM (DA MODIFICARE!) ---\n",
        "VLLM_ENDPOINT = f\"http://{HOST}:{PORT}/v1/chat/completions\" # Esempio: http://tuo_server_ip:8000/generate\n",
        "GENERALIST_MODEL_NAME = \"microsoft/Phi-3-mini-4k-instruct\" # Esempio: \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "MEDGEMMA_MODEL_NAME = \"unsloth/medgemma-4b-it-bnb-4bit\" # Esempio: \"google/medgemma-7b\"\n",
        "\n",
        "\n",
        "\n",
        "class Diagnosi(str, Enum):\n",
        "    alzheimer = \"alzheimer\"\n",
        "    mielodisplasia = \"mielodisplasia\"\n",
        "    leucemia = \"leucemia\"\n",
        "\n",
        "class PatientDescription(BaseModel):\n",
        "    name: str\n",
        "    age: str\n",
        "    diagnosi: Diagnosi\n",
        "    sintomi: str\n",
        "\n",
        "json_schema = PatientDescription.model_json_schema()\n",
        "\n",
        "\n",
        "payload = {\n",
        "        \"messages\": [   {\"role\": \"system\", \"content\": \"Sei un utile assistente medico. Devi estrarre informazioni dal testo fornito.\"},\n",
        "                        {\n",
        "                            \"role\": \"user\",\n",
        "                            \"content\": \"\"\"Paziente M.D., 72 anni, ricoverato per peggioramento delle difficolt√† cognitive iniziate 6 mesi fa,\n",
        "caratterizzate principalmente da deficit di memoria episodica, disorientamento temporale e spaziale.\n",
        "L'esame neurologico evidenzia lieve disprassia costruttiva. La RM cerebrale mostra atrofia ippocampale\n",
        "bilaterale e una modesta componente vascolare. CSF positivo per biomarker di Alzheimer (ridotta AŒ≤42, aumentata p-tau).\n",
        "Diagnosi provvisoria: Demenza di tipo Alzheimer con componente vascolare. Iniziato trattamento con Donepezil 5mg/die.\n",
        "Si programma follow-up tra 3 mesi.\"\"\",\n",
        "                        }\n",
        "                    ],\n",
        "        \"model\": GENERALIST_MODEL_NAME,\n",
        "        \"response_format\": {\n",
        "                            \"type\": \"json_schema\",\n",
        "                            \"json_schema\": {\n",
        "                                \"name\": \"car-description\",\n",
        "                                \"schema\": PatientDescription.model_json_schema()\n",
        "                            },\n",
        "                        },\n",
        "    }\n"
      ],
      "metadata": {
        "id": "T1tNQjnZT2mf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  async with httpx.AsyncClient(timeout=50) as client:\n",
        "    response = await client.post(VLLM_ENDPOINT, json=payload)\n",
        "    response.raise_for_status()\n",
        "    result = response.json()\n",
        "    response_text = result[\"choices\"][0][\"message\"][\"content\"]\n",
        "    # vLLM restituisce un array di \"text\" nei \"outputs\"\n",
        "except Exception as e:\n",
        "  print(e)"
      ],
      "metadata": {
        "id": "uyj2dtQVUlV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "id": "qmlN0pzoWSgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_riassunto_articolo = f\"Riassumi il seguente abstract scientifico in 3-4 frasi:\\n\\n{testo_articolo_neurologia}\\n\\nRiassunto:\"\n",
        "riassunto_generalista_articolo = await call_llm(prompt_riassunto_articolo, GENERALIST_MODEL_NAME)\n",
        "print(f\"\\nPrompt: {prompt_riassunto_articolo}...\")\n",
        "print(f\"Risposta (Generalista):\\n{riassunto_generalista_articolo}\")"
      ],
      "metadata": {
        "id": "vJZpqDEIQVIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\n--- Estrazione di Informazioni (Modello Generalista) ---\")\n",
        "prompt_estrazione = f\"\"\"Dal seguente testo clinico, estrai le seguenti informazioni in formato JSON:\n",
        "- Et√† del paziente\n",
        "- Diagnosi principale\n",
        "- Farmaci prescritti\n",
        "- Biomarker CSF menzionati\n",
        "\n",
        "Testo:\n",
        "{testo_clinico_neurologia}\n",
        "\n",
        "JSON:\"\"\"\n",
        "estrazione_generalista = await call_llm(prompt_estrazione, GENERALIST_MODEL_NAME, max_tokens=200, temperature=0.1) # Temperatura pi√π bassa per precisione\n",
        "print(f\"\\nPrompt: {prompt_estrazione}...\")\n",
        "print(f\"Risposta (Generalista):\\n{estrazione_generalista}\")\n",
        "\n",
        "# Prova a parsare il JSON se il modello risponde correttamente\n",
        "try:\n",
        "    json_output = json.loads(estrazione_generalista)\n",
        "    print(\"\\nInformazioni estratte (Parsate JSON):\")\n",
        "    print(json.dumps(json_output, indent=2))\n",
        "except json.JSONDecodeError:\n",
        "    print(\"\\nImpossibile parsare la risposta come JSON. Il modello potrebbe non aver formattato correttamente.\")"
      ],
      "metadata": {
        "id": "MT9cdIQxfgXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ds-8dPw9fgJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "  print(\"\\n--- Riassunto di Testo (MedGemma - Modello Specializzato) ---\")\n",
        "  # Riutilizziamo lo stesso prompt per un confronto diretto\n",
        "  riassunto_medgemma = await call_llm(prompt_riassunto_clinico, MEDGEMMA_MODEL_NAME)\n",
        "  print(f\"\\nPrompt: {prompt_riassunto_clinico}...\")\n",
        "  print(f\"Risposta (MedGemma):\\n{riassunto_medgemma}\")\n",
        "\n",
        "  print(\"\\n--- Estrazione di Informazioni (MedGemma - Modello Specializzato) ---\")\n",
        "  estrazione_medgemma = await call_llm(prompt_estrazione, MEDGEMMA_MODEL_NAME, max_tokens=200, temperature=0.1)\n",
        "  print(f\"\\nPrompt: {prompt_estrazione}\")\n",
        "  print(f\"Risposta (MedGemma):\\n{estrazione_medgemma}\")\n",
        "  try:\n",
        "      json_output_medgemma = json.loads(estrazione_medgemma)\n",
        "      print(\"\\nInformazioni estratte (MedGemma Parsate JSON):\")\n",
        "      print(json.dumps(json_output_medgemma, indent=2))\n",
        "  except json.JSONDecodeError:\n",
        "      print(\"\\nImpossibile parsare la risposta come JSON. Il modello potrebbe non aver formattato correttamente.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "s32LgKusdHtV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  print(\"\\nDiscussione dei risultati:\")\n",
        "  print(\"Notate le differenze tra le risposte del modello generalista e di MedGemma.\")\n",
        "  print(\"MedGemma dovrebbe dimostrare una maggiore comprensione del contesto medico e una migliore aderenza alle richieste specifiche del dominio.\")"
      ],
      "metadata": {
        "id": "a4J9zrKqfX9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from IPython.display import Image as IPImage, display, Markdown\n",
        "\n",
        "prompt = \"Descrivi questa MRI\"  # @param {type: \"string\"}\n",
        "\n",
        "# Image attribution: Stillwaterising, CC0, via Wikimedia Commons\n",
        "image_url = \"https://alzheimersnewstoday.com/wp-content/uploads/2014/10/WhiteMatterHyperintensities.jpg\" # \"https://upload.wikimedia.org/wikipedia/commons/c/c8/Chest_Xray_PA_3-8-2010.png\"  # @param {type: \"string\"}\n",
        "! wget -nc -q {image_url}\n",
        "image_filename = os.path.basename(image_url)\n",
        "image = Image.open(image_filename)"
      ],
      "metadata": {
        "id": "iusGDelOgHIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(IPImage(filename=image_filename, height=300))\n"
      ],
      "metadata": {
        "id": "7OUJ8whKuE6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_instruction = \"Sei un esperto neurologo.\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": [{\"type\": \"text\", \"text\": system_instruction}]\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\"type\": \"text\", \"text\": prompt},\n",
        "            {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}}\n",
        "        ]\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "_jFhVg3KoWbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VLLM_ENDPOINT"
      ],
      "metadata": {
        "id": "v9GQhVttVy8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EmIfz_8yWV8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MEDGEMMA_MODEL_NAME"
      ],
      "metadata": {
        "id": "Jq0gNg3FWMV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "headers = {\"Content-Type\": \"application/json\"}\n",
        "max_tokens = 500\n",
        "temperature = 0.7\n",
        "model_name = MEDGEMMA_MODEL_NAME\n",
        "payload = {\n",
        "    \"messages\": messages,\n",
        "    \"model\": model_name,\n",
        "    \"max_tokens\": max_tokens,\n",
        "    \"temperature\": temperature\n",
        "}\n",
        "\n",
        "try:\n",
        "  async with httpx.AsyncClient(timeout=50) as client:\n",
        "    response = await client.post(VLLM_ENDPOINT, json=payload)\n",
        "    response.raise_for_status()\n",
        "    result = response.json()\n",
        "    response_text = result[\"choices\"][0][\"message\"][\"content\"]\n",
        "    # vLLM restituisce un array di \"text\" nei \"outputs\"\n",
        "except requests.exceptions.ConnectionError:\n",
        "    print(\"Errore di connessione al server vLLM. Assicurati che l'endpoint sia corretto e il server sia attivo.\")\n",
        "except requests.exceptions.HTTPError as e:\n",
        "    print(f\"Errore HTTP dal server vLLM: {e}. Controlla il modello e i parametri.\")\n",
        "except Exception as e:\n",
        "    print(f\"Si √® verificato un errore inatteso: {e}\")\n"
      ],
      "metadata": {
        "id": "7nkAXSXeoo3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if response_text:\n",
        "\n",
        "  display(Markdown(f\"---\\n\\n**[ User ]**\\n\\n{prompt}\"))\n",
        "  display(IPImage(filename=image_filename, height=300))\n",
        "  display(Markdown(f\"---\\n\\n**[ MedGemma ]**\\n\\n{response_text}\\n\\n---\"))"
      ],
      "metadata": {
        "id": "MLV_8UA2opeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NER"
      ],
      "metadata": {
        "id": "b2kn1ueXdab-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "neurological_report = \"\"\"\n",
        "REPORT NEUROLOGICO\n",
        "Paziente: Bianchi Maria, F.\n",
        "Data di nascita: 12/05/1987\n",
        "Data della visita: 20/06/2025\n",
        "Diagnosi principale: Sclerosi Multipla Recidivante-Remittente (SM-RR)\n",
        "\n",
        "1. Anamnesi remota e familiare:\n",
        "Paziente di 38 anni, senza familiarit√† diretta per patologie demielinizzanti. Madre ipertesa, padre deceduto per infarto miocardico acuto a 62 anni. Nessuna storia familiare di patologie autoimmuni. Non allergie note a farmaci o alimenti.\n",
        "\n",
        "2. Anamnesi patologica prossima:\n",
        "La paziente riferisce esordio dei sintomi all‚Äôet√† di 28 anni con un episodio di neurite ottica retrobulbare a carico dell‚Äôocchio destro.\n",
        "Presenza VAF di TP53, RUNX1, SF3B1. Non riscontrate aberrazioni significative\n",
        "Attualmente in terapia di fondo con interferone beta-1a, associato a terapia sintomatica con baclofene per spasticit√† e pregabalin per disestesie dolorose. Segue regolari controlli ambulatoriali neurologici.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "rimosso = \"\"\"\n",
        "\n",
        "3. Esame obiettivo neurologico:\n",
        "- Stato mentale: vigile, orientata nel tempo e nello spazio, linguaggio fluente, memoria a breve e lungo termine conservata.\n",
        "- Nervi cranici: papilla ottica pallida a destra, lieve nistagmo orizzontale bilaterale. Motilit√† oculare conservata salvo leggera diplopia per sguardi laterali estremi. Udito nei limiti. Riflessi corneali presenti bilateralmente. Mimica facciale simmetrica. Faringeo e motilit√† linguale normali.\n",
        "- Forza muscolare: lievissima ipoastenia dell‚Äôarto superiore destro (4+/5), tono muscolare aumentato agli arti inferiori con segno di spasticit√† lieve bilaterale.\n",
        "- Sensibilit√†: ipoestesia tattile a calza e guanto, lieve disestesia alla palpazione profonda degli arti inferiori.\n",
        "- Riflessi osteotendinei: iperreflessia diffusa agli arti inferiori, clono achilleo bilaterale, segno di Babinski positivo bilateralmente.\n",
        "- Coordinazione: dismetria lieve all‚Äôindice-naso a destra, segno di Romberg positivo, andatura atassica con base allargata.\n",
        "- Marcia e stazione eretta: deambulazione autonoma ma instabile su superfici irregolari; difficolt√† nell‚Äôesecuzione della marcia tandem.\n",
        "\n",
        "4. Esami strumentali:\n",
        "- RM encefalo e midollo cervicale (ultima eseguita il 10/05/2025): multiple placche iperintense in T2 e FLAIR a livello periventricolare, del corpo calloso e tronco encefalico; una placca cervicale a C2-C3 con lieve enhancement di contrasto, indicativa di lesione attiva. Nessun segno di atrofia corticale significativa.\n",
        "- Potenziali evocati visivi: prolungamento della latenza P100 a destra.\n",
        "- Liquor (ultimo prelievo): presenza di bande oligoclonali IgG assenti nel siero, proteinorrachia 58 mg/dL.\n",
        "\n",
        "5. Considerazioni cliniche:\n",
        "Il quadro clinico e neuroradiologico √® coerente con sclerosi multipla a decorso recidivante-remittente in fase di parziale attivit√† di malattia. Si rileva una discreta compromissione funzionale soprattutto a livello della coordinazione e dell‚Äôequilibrio, con tendenza alla spasticit√† degli arti inferiori e disturbi sensitivi persistenti.\n",
        "\n",
        "Nonostante la terapia di fondo con interferone beta-1a, si registrano ricadute cliniche e segni di progressione radiologica, suggerendo una possibile risposta subottimale al trattamento attuale.\n",
        "\n",
        "6. Piano terapeutico e raccomandazioni:\n",
        "- Valutare switch terapeutico verso farmaco di seconda linea (opzione natalizumab o fingolimod) previa rivalutazione del profilo rischio-beneficio e screening per JC virus.\n",
        "- Intensificare fisioterapia neuromotoria con obiettivo di potenziamento dell‚Äôequilibrio e riduzione della spasticit√†.\n",
        "- Valutare integrazione con logopedia in caso di peggioramento di disartria o disturbi di deglutizione.\n",
        "- Continuare terapia sintomatica per spasticit√† e neuropatia dolorosa.\n",
        "- Programmare nuovo controllo RM encefalo e midollo tra 6 mesi o in caso di nuova ricaduta.\n",
        "- Monitoraggio ematochimico periodico per parametri di sicurezza legati alla terapia immunomodulante.\n",
        "\n",
        "Firma del neurologo:\n",
        "Dott. Giovanni Rossi, Neurologo\n",
        "Unit√† Operativa di Neurologia\n",
        "Ospedale Maggiore, Milano\n",
        "\"\"\"\n",
        "display(Markdown(f\"---\\n\\n**[ User ]**\\n\\n{neurological_report}\"))\n",
        "\n"
      ],
      "metadata": {
        "id": "htJwsZF5e-xF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truth = {\n",
        "    \"nome_paziente\": \"Bianchi Maria\",\n",
        "    \"data_nascita\": \"12/05/1987\",\n",
        "    \"data_visita\": \"20/06/2025\",\n",
        "    \"diagnosi\": \"Sclerosi Multipla Recidivante-Remittente\",\n",
        "    \"et√†\": 38,\n",
        "    \"anamnesi_familiare\": {\n",
        "        \"patologie_autoimmuni\": False,\n",
        "        \"ipertensione\": True,\n",
        "        \"patologie_cardiovascolari\": True\n",
        "    },\n",
        "    \"et√†_primo_sintomo\": 28,\n",
        "    \"ricadute\": [\n",
        "        {\n",
        "            \"sintomi\": \"neurite ottica retrobulbare occhio destro\",\n",
        "            \"terapia\": \"steroidi ad alto dosaggio\"\n",
        "        },\n",
        "        {\n",
        "            \"sintomi\": \"parestesie arti inferiori, lieve atassia\",\n",
        "            \"terapia\": \"recupero spontaneo\"\n",
        "        },\n",
        "        {\n",
        "            \"sintomi\": \"diplopia intermittente\",\n",
        "            \"terapia\": \"interferone beta-1a\"\n",
        "        },\n",
        "        {\n",
        "            \"sintomi\": \"instabilit√† alla marcia, difficolt√† di coordinazione mano destra\",\n",
        "            \"terapia\": \"interferone beta-1a\"\n",
        "        }\n",
        "    ],\n",
        "    \"terapia_attuale\": {\n",
        "        \"di_fondo\": \"interferone beta-1a\",\n",
        "        \"sintomatica\": [\"baclofene\", \"pregabalin\"]\n",
        "    },\n",
        "    \"obiettivit√†_neurologica\": {\n",
        "        \"deficit_visivi\": \"papilla ottica pallida, nistagmo, diplopia\",\n",
        "        \"deficit_motori\": \"ipoastenia arto superiore destro, spasticit√† arti inferiori\",\n",
        "        \"deficit_sensitivi\": \"ipoestesia, disestesia\",\n",
        "        \"riflessi\": \"iperreflessia, clono, Babinski positivo\",\n",
        "        \"coordinazione\": \"dismetria, Romberg positivo, atassia\"\n",
        "    },\n",
        "    \"reperti_strumentali\": {\n",
        "        \"lesioni_encefaliche\": \"placche T2/FLAIR periventricolari, tronco encefalico, corpo calloso\",\n",
        "        \"lesioni_midollo_cervicale\": \"placca C2-C3 attiva\"\n",
        "    },\n",
        "    \"liquor\": {\n",
        "        \"bande_oligoclonali\": \"positive\",\n",
        "        \"proteinorrachia_mg_dl\": 58\n",
        "    },\n",
        "    \"raccomandazioni\": [\n",
        "        \"valutare switch a farmaco di seconda linea\",\n",
        "        \"intensificare fisioterapia\",\n",
        "        \"valutare logopedia\",\n",
        "        \"monitoraggio RM e esami ematochimici\"\n",
        "    ]\n",
        "}\n"
      ],
      "metadata": {
        "id": "hv-0yw7PZdqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "empty_schema = {\n",
        "    \"nome_paziente\": \"\",\n",
        "    \"data_nascita\": \"\",\n",
        "    \"data_visita\": \"\",\n",
        "    \"diagnosi\": \"\",\n",
        "    \"et√†\": None,\n",
        "    \"anamnesi_familiare\": {\n",
        "        \"patologie_autoimmuni\": None,\n",
        "        \"ipertensione\": None,\n",
        "        \"patologie_cardiovascolari\": None\n",
        "    },\n",
        "    \"et√†_primo_sintomo\": None,\n",
        "    \"ricadute\": [\n",
        "        {\n",
        "            \"sintomi\": \"\",\n",
        "            \"terapia\": \"\"\n",
        "        }\n",
        "    ],\n",
        "    \"terapia_attuale\": {\n",
        "        \"di_fondo\": \"\",\n",
        "        \"sintomatica\": []\n",
        "    },\n",
        "    \"obiettivit√†_neurologica\": {\n",
        "        \"deficit_visivi\": \"\",\n",
        "        \"deficit_motori\": \"\",\n",
        "        \"deficit_sensitivi\": \"\",\n",
        "        \"riflessi\": \"\",\n",
        "        \"coordinazione\": \"\"\n",
        "    },\n",
        "    \"reperti_strumentali\": {\n",
        "        \"lesioni_encefaliche\": \"\",\n",
        "        \"lesioni_midollo_cervicale\": \"\"\n",
        "    },\n",
        "    \"liquor\": {\n",
        "        \"bande_oligoclonali\": \"\",\n",
        "        \"proteinorrachia_mg_dl\": None\n",
        "    },\n",
        "    \"raccomandazioni\": []\n",
        "}\n"
      ],
      "metadata": {
        "id": "uJNbs5bwdbsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "schema = json.dumps(empty_schema)"
      ],
      "metadata": {
        "id": "0-lF9rE3foGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "schema"
      ],
      "metadata": {
        "id": "sP6ldQjzgfp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chiavi = \"\"\"\n",
        "- nome_paziente\n",
        "- data_nascita\n",
        "- data_visita\n",
        "- diagnosi\n",
        "- et√†\n",
        "- mutazioni\n",
        "- citogenetica\n",
        "- anamnesi_familiare.patologie_autoimmuni\n",
        "- anamnesi_familiare.ipertensione\n",
        "- anamnesi_familiare.patologie_cardiovascolari\n",
        "- et√†_primo_sintomo\n",
        "- ricadute[].sintomi\n",
        "- ricadute[].terapia\n",
        "- terapia_attuale.di_fondo\n",
        "- terapia_attuale.sintomatica\n",
        "- obiettivit√†_neurologica.deficit_visivi\n",
        "- obiettivit√†_neurologica.deficit_motori\n",
        "- obiettivit√†_neurologica.deficit_sensitivi\n",
        "- obiettivit√†_neurologica.riflessi\n",
        "- obiettivit√†_neurologica.coordinazione\n",
        "- reperti_strumentali.lesioni_encefaliche\n",
        "- reperti_strumentali.lesioni_midollo_cervicale\n",
        "- liquor.bande_oligoclonali\n",
        "- liquor.proteinorrachia_mg_dl\n",
        "- raccomandazioni\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "z3q_34rKlMif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Estrazione di Informazioni (MedGemma Zero-Shot) ---\")\n",
        "prompt_estrazione = f\"\"\"Dal seguente testo clinico: {neurological_report}\\n Estrai le seguenti informazioni in formato JSON: {chiavi}.\\n Se non trovi alcuni campi lasciali vuoti.\n",
        "\n",
        "JSON:\"\"\"\n",
        "print(prompt_estrazione)\n"
      ],
      "metadata": {
        "id": "pRPPhjXXjxCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "  print(\"\\n--- Riassunto di Testo (MedGemma - Modello Specializzato) ---\")\n",
        "\n",
        "  print(\"\\n--- Estrazione di Informazioni (MedGemma - Modello Specializzato) ---\")\n",
        "  estrazione_medgemma = await call_llm(prompt_estrazione, MEDGEMMA_MODEL_NAME, max_tokens=200, temperature=0.1)\n",
        "  print(f\"\\nPrompt: {prompt_estrazione}\")\n",
        "  print(f\"Risposta (MedGemma):\\n{estrazione_medgemma}\")\n",
        "  try:\n",
        "      json_output_medgemma = json.loads(estrazione_medgemma)\n",
        "      print(\"\\nInformazioni estratte (MedGemma Parsate JSON):\")\n",
        "      print(json.dumps(json_output_medgemma, indent=2))\n",
        "  except json.JSONDecodeError:\n",
        "      print(\"\\nImpossibile parsare la risposta come JSON. Il modello potrebbe non aver formattato correttamente.\")"
      ],
      "metadata": {
        "id": "QVOnsbI0kklt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import httpx\n",
        "\n",
        "# --- CONFIGURAZIONE DEL TUO VLLM (DA MODIFICARE!) ---\n",
        "VLLM_ENDPOINT = f\"http://{HOST}:{PORT}/v1/chat/completions\" # Esempio: http://tuo_server_ip:8000/generate\n",
        "GENERALIST_MODEL_NAME = \"microsoft/Phi-3-mini-4k-instruct\" # Esempio: \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "MEDGEMMA_MODEL_NAME = \"unsloth/medgemma-4b-it-bnb-4bit\" # Esempio: \"google/medgemma-7b\"\n",
        "\n",
        "# Funzione per inviare una richiesta al tuo server vLLM\n",
        "async def call_llm(prompt, model_name, max_tokens=150, temperature=0.7):\n",
        "    headers = {\"Content-Type\": \"application/json\"}\n",
        "    payload = {\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "        \"model\": model_name,\n",
        "        \"max_tokens\": max_tokens,\n",
        "        \"temperature\": temperature\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        async with httpx.AsyncClient(timeout=50) as client:\n",
        "          response = await client.post(VLLM_ENDPOINT, json=payload)\n",
        "          response.raise_for_status()\n",
        "          result = response.json()\n",
        "          response_text = result[\"choices\"][0][\"message\"][\"content\"]\n",
        "          # vLLM restituisce un array di \"text\" nei \"outputs\"\n",
        "          return response_text # result['outputs'][0]['text'].strip()\n",
        "    except requests.exceptions.ConnectionError:\n",
        "        return \"Errore di connessione al server vLLM. Assicurati che l'endpoint sia corretto e il server sia attivo.\"\n",
        "    except requests.exceptions.HTTPError as e:\n",
        "        return f\"Errore HTTP dal server vLLM: {e}. Controlla il modello e i parametri.\"\n",
        "    except Exception as e:\n",
        "        return f\"Si √® verificato un errore inatteso: {e}\"\n",
        "\n",
        "print(\"Pronto a interagire con gli LLM tramite vLLM.\")\n",
        "print(\"Ricorda di configurare YOUR_VLLM_ENDPOINT, GENERALIST_MODEL_NAME e MEDGEMMA_MODEL_NAME!\")\n",
        "\n"
      ],
      "metadata": {
        "id": "9IE2EnqWkkcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## Generalista\n",
        "general_model = 'abhishekchohan/gemma-3-12b-it-quantized-W4A16'\n",
        "print(\"\\n--- Riassunto di Testo (MedGemma - Modello Specializzato) ---\")\n",
        "\n",
        "print(\"\\n--- Estrazione di Informazioni (MedGemma - Modello Specializzato) ---\")\n",
        "estrazione_medgemma = await call_llm(prompt_estrazione, general_model, max_tokens=1000, temperature=0.7)\n",
        "try:\n",
        "    json_output_medgemma = json.loads(estrazione_medgemma)\n",
        "    print(\"\\nInformazioni estratte (MedGemma Parsate JSON):\")\n",
        "    print(json.dumps(json_output_medgemma, indent=2))\n",
        "except json.JSONDecodeError:\n",
        "    print(\"\\nImpossibile parsare la risposta come JSON. Il modello potrebbe non aver formattato correttamente.\")"
      ],
      "metadata": {
        "id": "cbNUIYtVpoam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if response_text:\n",
        "\n",
        "  display(Markdown(f\"---\\n\\n**[ User ]**\\n\\n{neurological_report}\"))\n",
        "  display(Markdown(f\"---\\n\\n**[ MedGemma ]**\\n\\n{estrazione_medgemma}\\n\\n---\"))"
      ],
      "metadata": {
        "id": "CZzbm1C6o5PX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prefix_instruction = \"Leggi il seguente report neurologico e compila questo JSON di output in italiano secondo lo schema fornito. Riporta solo le informazioni effettivamente presenti nel testo e mantieni la struttura invariata. Se un campo non √® menzionato, lascialo vuoto o nullo. Ritorna solo il JSON\"\n"
      ],
      "metadata": {
        "id": "auPrGNTZdfEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_instruction = \"Sei un esperto neurologo.\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": [{\"type\": \"text\", \"text\": system_instruction}, {\"type\": \"text\", \"text\": prefix_instruction},]\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\"type\": \"text\", \"text\": neurological_report},\n",
        "            {\"type\": \"text\", \"text\": schema }\n",
        "        ]\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "JjOGsULWeahR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "headers = {\"Content-Type\": \"application/json\"}\n",
        "max_tokens = 500\n",
        "temperature = 0.7\n",
        "model_name = MEDGEMMA_MODEL_NAME\n",
        "payload = {\n",
        "    \"messages\": messages,\n",
        "    \"model\": model_name,\n",
        "    \"max_tokens\": max_tokens,\n",
        "    \"temperature\": temperature\n",
        "}\n",
        "\n",
        "try:\n",
        "  async with httpx.AsyncClient(timeout=50) as client:\n",
        "    response = await client.post(VLLM_ENDPOINT, json=payload)\n",
        "    response.raise_for_status()\n",
        "    result = response.json()\n",
        "    response_text = result[\"choices\"][0][\"message\"][\"content\"]\n",
        "    # vLLM restituisce un array di \"text\" nei \"outputs\"\n",
        "except requests.exceptions.ConnectionError:\n",
        "    print(\"Errore di connessione al server vLLM. Assicurati che l'endpoint sia corretto e il server sia attivo.\")\n",
        "except requests.exceptions.HTTPError as e:\n",
        "    print(f\"Errore HTTP dal server vLLM: {e}. Controlla il modello e i parametri.\")\n",
        "except Exception as e:\n",
        "    print(f\"Si √® verificato un errore inatteso: {e}\")"
      ],
      "metadata": {
        "id": "47cHPFWleaYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response_text"
      ],
      "metadata": {
        "id": "C46epZxTgWlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if response_text:\n",
        "\n",
        "  display(Markdown(f\"---\\n\\n**[ User ]**\\n\\n{neurological_report}\"))\n",
        "  display(Markdown(f\"---\\n\\n**[ MedGemma ]**\\n\\n{response_text}\\n\\n---\"))"
      ],
      "metadata": {
        "id": "0Fuc71BGeaUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 2. Segmentazione di Immagini in Neurologia: Identificare e Delineare\n",
        "\n",
        "La **segmentazione di immagini** √® una tecnica di visione artificiale che consiste nel suddividere un'immagine in regioni o oggetti con propriet√† simili. In medicina, √® fondamentale per:\n",
        "\n",
        "* **Quantificazione:** Misurare il volume di lesioni, tumori o atrofia cerebrale.\n",
        "* **Navigazione Chirurgica:** Delineare le aree di interesse per interventi precisi.\n",
        "* **Diagnosi:** Aiutare a identificare e localizzare patologie."
      ],
      "metadata": {
        "id": "2MLqvpvGeaJU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 2.1. MedSAM: Un Modello Fondamentale per la Segmentazione Medica\n",
        "\n",
        "**MedSAM (Medical Segment Anything Model)** √® un esempio di \"foundation model\" adattato al dominio medico. Nasce dal successo del modello Segment Anything Model (SAM) di Meta AI, addestrato su una quantit√† enorme di immagini generiche. MedSAM √® stato poi specializzato per riconoscere e segmentare una vasta gamma di strutture anatomiche e patologie nelle immagini mediche con notevole accuratezza, anche con pochi esempi o con input minimi (es. un singolo punto).\n",
        "\n",
        "**Nota importante per la demo:** L'esecuzione di MedSAM su immagini complesse pu√≤ richiedere risorse computazionali significative (GPU dedicate e RAM). Per questa sessione, dimostreremo il concetto: potremmo mostrare l'output pre-calcolato su un'immagine di esempio, oppure, se le risorse di Colab lo permettono in tempo reale per un esempio semplificato, eseguiremo una versione pi√π leggera o un modello simile.\n",
        "\n",
        "#### **Esempio Concettuale di Segmentazione**\n",
        "\n",
        "Simuleremo il caricamento di un'immagine di risonanza magnetica cerebrale e visualizzeremo un esempio di segmentazione di una lesione.\n"
      ],
      "metadata": {
        "id": "uWkl5AVLpKGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "# --- Parte 1: Download e Visualizzazione di un'Immagine Medica di Esempio ---\n",
        "# Useremo un'immagine di esempio disponibile pubblicamente o genereremo una dummy.\n",
        "# Per una demo reale, potresti avere un'immagine di RM cerebrale con una lesione.\n",
        "\n",
        "# Funzione per scaricare un'immagine\n",
        "def download_image(url):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status() # Lancia un errore per risposte http errate\n",
        "        img = Image.open(BytesIO(response.content)).convert(\"L\") # Converti in scala di grigi\n",
        "        return np.array(img)\n",
        "    except Exception as e:\n",
        "        print(f\"Errore durante il download o l'apertura dell'immagine: {e}\")\n",
        "        # Genera un'immagine dummy se il download fallisce\n",
        "        print(\"Generazione di un'immagine di esempio sintetica...\")\n",
        "        dummy_img = np.zeros((128, 128), dtype=np.uint8)\n",
        "        # Aggiungi una forma semplice per simulare una struttura\n",
        "        dummy_img[30:60, 30:60] = 150 # Regione grigia\n",
        "        dummy_img[70:90, 70:90] = 200 # Regione pi√π chiara\n",
        "        return dummy_img"
      ],
      "metadata": {
        "id": "NbI77jW0pANs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# URL di un'immagine di esempio (puoi sostituirla con una tua immagine medicale)\n",
        "# Questa √® un'immagine generica di un cervello.\n",
        "image_url = 'https://www.learnhaem.com/wp-content/uploads/2020/02/aml-m1-1024x691.png' # @param\n",
        "# Puoi anche caricare un'immagine direttamente su Colab e usarla:\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "# img_path = list(uploaded.keys())[0]\n",
        "# original_image = np.array(Image.open(img_path).convert(\"L\"))\n",
        "\n",
        "original_image = download_image(image_url)\n",
        "\n",
        "if original_image is not None:\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(original_image, cmap='gray')\n",
        "    plt.title('Immagine RM Cerebrale di Esempio')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# --- Parte 2: Simulazione Concettuale della Segmentazione ---\n",
        "# Per una demo live con MedSAM, dovresti installare le librerie MedSAM e caricarne un checkpoint.\n",
        "# Dato il tempo limitato e le risorse, mostreremo il CONCETTO di mascheramento.\n",
        "\n",
        "# Creiamo una maschera di segmentazione FITTIZIA per l'esempio\n",
        "# Questa maschera simula la segmentazione di una lesione o di una struttura specifica.\n",
        "segmentation_mask = np.zeros_like(original_image, dtype=np.uint8)\n",
        "# Simula una lesione nella parte superiore destra dell'immagine\n",
        "mask_center_x, mask_center_y = int(original_image.shape[1] * 0.7), int(original_image.shape[0] * 0.3)\n",
        "mask_radius = int(min(original_image.shape) * 0.15)\n",
        "Y, X = np.ogrid[:original_image.shape[0], :original_image.shape[1]]\n",
        "dist_from_center = np.sqrt((X - mask_center_x)**2 + (Y - mask_center_y)**2)\n",
        "segmentation_mask[dist_from_center < mask_radius] = 1 # Imposta a 1 dove c'√® la \"lesione\"\n",
        "\n",
        "# Combina l'immagine originale con la maschera di segmentazione\n",
        "# Sovrapponiamo la maschera sulla scala di blu per visualizzare l'area segmentata\n",
        "segmented_overlay = np.stack([original_image, original_image, original_image], axis=-1)\n",
        "segmented_overlay[segmentation_mask == 1, 0] = 255 # Rende rossa la zona segmentata\n",
        "segmented_overlay[segmentation_mask == 1, 1] = 0\n",
        "segmented_overlay[segmentation_mask == 1, 2] = 0\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(original_image, cmap='gray')\n",
        "plt.title('Immagine Originale')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(segmented_overlay)\n",
        "plt.title('Immagine Segmentata (Lesione Evidenziata)')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nSpiegazione della Segmentazione:\")\n",
        "print(\"In questo esempio concettuale, abbiamo simulato come un modello di IA (come MedSAM)\")\n",
        "print(\"potrebbe identificare e delineare una specifica area di interesse, come una lesione o\")\n",
        "print(\"una struttura anatomica. L'area rossa indica la regione 'segmentata' dal modello.\")\n",
        "print(\"Questo √® fondamentale per la quantificazione e la pianificazione diagnostica/terapeutica.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "wH06fQB3pdgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MedSAM: Segmentazione per immagini mediche"
      ],
      "metadata": {
        "id": "sFtt0sn8rHMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data download\n",
        "url = \"https://drive.google.com/drive/folders/15hE_hEevLcIEq5Sf8hLotlMlA1KH_q06?usp=sharing\"\n",
        "import gdown\n",
        "gdown.download_folder(url, quiet=True)"
      ],
      "metadata": {
        "id": "_SPP_r8xv15c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Environment setup\n",
        "!pip install torch==2.4.1 torchvision==0.19.1 --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install jax==0.4.33\n",
        "!pip install numpy==1.24\n",
        "\n",
        "!pip install open_clip_torch==2.23.0\n",
        "!pip install git+https://github.com/openai/CLIP.git\n",
        "!pip install grad_cam==1.4.6\n",
        "!pip install transformers==4.35.2"
      ],
      "metadata": {
        "id": "Fx-3QxHFrFaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get repo and install env\n",
        "!git clone https://github.com/HealthX-Lab/MedCLIP-SAMv2\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"Torchvision version:\", torchvision.__version__)\n",
        "print(\"CUDA is available:\", torch.cuda.is_available())\n",
        "import sys\n",
        "!{sys.executable} -m pip install opencv-python matplotlib\n",
        "!{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n",
        "\n",
        "!wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n"
      ],
      "metadata": {
        "id": "YIhNXzKRpeb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd MedCLIP-SAMv2/saliency_maps"
      ],
      "metadata": {
        "id": "50aMpswivJtV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import os\n",
        "import torch\n",
        "import clip\n",
        "import cv2\n",
        "import sys\n",
        "import numpy as np\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from transformers import CLIPProcessor\n",
        "from scripts.plot import generate_shades_with_alpha, plot_text_with_colors, visualize_vandt_heatmap\n",
        "from scripts.methods import vision_heatmap_iba, text_heatmap_iba\n",
        "from transformers import AutoModel, AutoProcessor, AutoTokenizer\n",
        "from PIL import Image, ImageOps\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def plot(model, image, text, vbeta=0.1, vvar=1, vlayer=9, tbeta=0.1, tvar=1, tlayer=9):\n",
        "    # Preprocess image\n",
        "    image = Image.open(image).convert('RGB')\n",
        "    image_feat = processor(images=image, return_tensors=\"pt\")['pixel_values'].to(device) # 3*224*224\n",
        "    # Tokenize text\n",
        "    text_ids = torch.tensor([tokenizer.encode(text, add_special_tokens=True)]).to(device)\n",
        "    text_words = tokenizer.convert_ids_to_tokens(text_ids[0].tolist())\n",
        "    # Train information bottleneck on image\n",
        "    print(\"Training M2IB on the image...\")\n",
        "    vmap = vision_heatmap_iba(text_ids, image_feat, model, vlayer, vbeta, vvar)\n",
        "    # Train information bottleneck on text\n",
        "    print(\"Training M2IB on the text...\")\n",
        "    tmap = text_heatmap_iba(text_ids, image_feat, model, tlayer, tbeta, tvar)\n",
        "    # Just for demonstration purposes\n",
        "    image_under = processor2(images=image, return_tensors=\"pt\", do_normalize=False)['pixel_values'][0].permute(1,2,0)\n",
        "    visualize_vandt_heatmap(tmap, vmap, text_words, image_under)\n",
        "    img = np.array(image)\n",
        "    vmap = cv2.resize(np.array(vmap),(img.shape[1],img.shape[0]),interpolation=cv2.INTER_NEAREST)*255\n",
        "    return vmap\n",
        "\n",
        "def overlay_segmentation(rgb_image, segmentation, alpha=0.4):\n",
        "    \"\"\"\n",
        "    Overlays a red segmentation mask on top of a grayscale-looking RGB image.\n",
        "\n",
        "    Parameters:\n",
        "        rgb_image (PIL.Image.Image): RGB image loaded with PIL (even if it looks grayscale).\n",
        "        segmentation (np.ndarray): 2D binary array (same width/height as image) where mask == 1 indicates the segmented area.\n",
        "        alpha (float): Transparency of the segmentation overlay.\n",
        "    \"\"\"\n",
        "    if not isinstance(rgb_image, Image.Image):\n",
        "        raise TypeError(\"rgb_image must be a PIL.Image.Image object\")\n",
        "\n",
        "    image_np = np.array(rgb_image).astype(np.float32) / 255.0  # Normalize to [0,1]\n",
        "    # print(image_np.shape)\n",
        "    # print(segmentation.shape)\n",
        "\n",
        "    if segmentation.shape != image_np.shape[:2]:\n",
        "        raise ValueError(\"Segmentation mask must have the same width and height as the image\")\n",
        "\n",
        "    # Create red overlay where segmentation is 1\n",
        "    red_mask = np.zeros_like(image_np)\n",
        "    red_mask[..., 0] = 1  # Set red channel\n",
        "\n",
        "    # Blend the red mask with the image where segmentation is 1\n",
        "    overlay = np.where(segmentation[..., None].astype(bool),\n",
        "                       (1 - alpha) * image_np + alpha * red_mask,\n",
        "                       image_np)\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(overlay)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "NdR2AT_psSIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModel.from_pretrained(\"chuhac/BiomedCLIP-vit-bert-hf\", trust_remote_code=True).to(device)\n",
        "processor = AutoProcessor.from_pretrained(\"chuhac/BiomedCLIP-vit-bert-hf\", trust_remote_code=True)\n",
        "processor2 = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch16\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"chuhac/BiomedCLIP-vit-bert-hf\", trust_remote_code=True)"
      ],
      "metadata": {
        "id": "qjZmHGwps6UC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "RgTmAL7oxzFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nCdLnwifxyvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!file /content/MedCLIP-SAMv2/saliency_maps/data/WhiteMatterHyperintensities.jpg\n"
      ],
      "metadata": {
        "id": "dGoDDvl7z1BP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## Saliency Maps\n",
        "image_path = \"/content/MedCLIP-SAMv2/saliency_maps/data/Breast-Mammo/1-142.jpg\" # @param {type:\"string\"}\n",
        "text = \"segment the lesion in X-ray mammography\" # @param {type:\"string\"}\n",
        "vmap = plot(model, image_path, text)"
      ],
      "metadata": {
        "id": "oRzCghXhtNmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## Postprocessing\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "kmeans = KMeans(n_clusters=2,random_state=10)\n",
        "attn_weights = vmap / 255\n",
        "# Keep only high attention weight scores\n",
        "h, w = attn_weights.shape\n",
        "attn_wg_threshold = 0.75 #@param {type:\"slider\", min:0.1, max:1.0, step:0.05}\n",
        "filtered_attn_weights = attn_weights > attn_wg_threshold\n",
        "attn_weights = attn_weights*filtered_attn_weights\n",
        "image = cv2.resize(attn_weights, (256, 256),interpolation=cv2.INTER_NEAREST)\n",
        "flat_image = image.reshape(-1, 1)\n",
        "\n",
        "labels = kmeans.fit_predict(flat_image)\n",
        "\n",
        "segmented_image = labels.reshape(256, 256)\n",
        "\n",
        "centroids = kmeans.cluster_centers_.flatten()\n",
        "\n",
        "# Identify the background cluster (assuming it has the lowest centroid value)\n",
        "background_cluster = np.argmin(centroids)\n",
        "\n",
        "# Mark background pixels as 0 and foreground pixels as 1\n",
        "segmented_image = np.where(segmented_image == background_cluster, 0, 1)\n",
        "\n",
        "segmented_image = cv2.resize(segmented_image, (w,h),interpolation=cv2.INTER_NEAREST)\n",
        "segmented_image = segmented_image.astype(np.uint8)*255\n",
        "\n",
        "nb_blobs, im_with_separated_blobs, stats, _ = cv2.connectedComponentsWithStats(segmented_image)\n",
        "sizes = stats[:, cv2.CC_STAT_AREA]\n",
        "\n",
        "# Sort sizes (ignoring the background at index 0)\n",
        "sorted_sizes = sorted(sizes[1:], reverse=True)\n",
        "\n",
        "# Change this here if you want to segment more than one contour\n",
        "num_contours = 1\n",
        "\n",
        "# Determine the top K sizes\n",
        "top_k_sizes = sorted_sizes[:num_contours]\n",
        "\n",
        "im_result = np.zeros_like(im_with_separated_blobs)\n",
        "\n",
        "for index_blob in range(1, nb_blobs):\n",
        "    if sizes[index_blob] in top_k_sizes:\n",
        "        im_result[im_with_separated_blobs == index_blob] = 255\n",
        "\n",
        "segmented_image = im_result\n",
        "\n",
        "cv2.imwrite(\"/content/MedCLIP-SAMv2/postprocessed_map.png\", segmented_image)\n",
        "\n",
        "# plt.imshow(segmented_image,cmap=\"gray\")\n",
        "overlay_segmentation(rgb_image=Image.open(image_path).convert('RGB'), segmentation=segmented_image)"
      ],
      "metadata": {
        "id": "oJrM7soBtW9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RKo4UfQP4ZfP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}